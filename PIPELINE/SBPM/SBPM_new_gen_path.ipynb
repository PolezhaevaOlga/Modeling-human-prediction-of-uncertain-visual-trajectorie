{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211af46f-8927-4a5e-ab97-fadf3c6fca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import scipy.io\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5875d5a2-ac2a-49e1-b143-142eef3a1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_type(file_path):\n",
    "    if \"iid_same\" in file_path:\n",
    "        return \"iid_same\"\n",
    "    elif \"iid_opposite\" in file_path:\n",
    "        return \"iid_opposite\"\n",
    "    elif \"rdw_same\" in file_path:\n",
    "        return \"rdw_same\"\n",
    "    elif \"rdw_opposite\" in file_path:\n",
    "        return \"rdw_opposite\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1529ea-55d6-4df8-9cc1-be79d304ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv =  sorted(str(p) for p in pathlib.Path(\"../data/new_path_2\").glob(\"*.csv\"))\n",
    "sorted_files = sorted(data_csv, key=get_file_type)\n",
    "data_csv_iid_op = [file for file in sorted_files if get_file_type(file) == \"iid_opposite\"]\n",
    "data_csv_iid_same = [file for file in sorted_files if get_file_type(file) == \"iid_same\"]\n",
    "data_csv_rdw_op = [file for file in sorted_files if get_file_type(file) == \"rdw_opposite\"]\n",
    "data_csv_rdw_same = [file for file in sorted_files if get_file_type(file) == \"rdw_same\"]\n",
    "\n",
    "data_sim_iid_op = [pd.read_csv(file, header=None, sep =';').to_numpy() for file in data_csv_iid_op]\n",
    "data_sim_iid_same = [pd.read_csv(file, header=None, sep =';').to_numpy() for file in data_csv_iid_same]\n",
    "data_sim_rdw_op = [pd.read_csv(file, header=None, sep =';').to_numpy() for file in data_csv_rdw_op]\n",
    "data_sim_rdw_same = [pd.read_csv(file, header=None, sep =';').to_numpy() for file in data_csv_rdw_same]\n",
    "\n",
    "#data_sim_iid_op = data_sim_iid_op[28:]\n",
    "#data_sim_iid_same = data_sim_iid_same[28:]\n",
    "\n",
    "#data_sim_rdw_op = data_sim_rdw_op[28:]\n",
    "#data_sim_rdw_same = data_sim_rdw_same[28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efe7a63-ae12-49ac-a418-cd1d21e4140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating condition: iid opposite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iid opposite: 100%|████████████████████████████████████████████████████████████████████| 28/28 [00:42<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating condition: iid same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iid same: 100%|████████████████████████████████████████████████████████████████████████| 28/28 [00:41<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating condition: rdw opposite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rdw opposite: 100%|████████████████████████████████████████████████████████████████████| 28/28 [00:40<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating condition: rdw same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rdw same: 100%|████████████████████████████████████████████████████████████████████████| 28/28 [00:41<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import trange\n",
    "\n",
    "nsmooth = 5\n",
    "noise = 3\n",
    "nbias = 2\n",
    "n = 200\n",
    "indices = np.arange(0, 100)\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (\"iid opposite\", data_sim_iid_op),\n",
    "    (\"iid same\", data_sim_iid_same),\n",
    "    (\"rdw opposite\", data_sim_rdw_op),\n",
    "    (\"rdw same\", data_sim_rdw_same),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for condition_name, list_of_datasets in conditions:\n",
    "    print(f\"\\nSimulating condition: {condition_name}\")\n",
    "\n",
    "    for file_idx, data in enumerate(tqdm.tqdm(list_of_datasets, desc=f\"{condition_name}\")):\n",
    "        df_results_all = {}\n",
    "        num_indices = len(indices)\n",
    "        rmdl = np.zeros(num_indices)\n",
    "        nmdl = np.zeros(num_indices)\n",
    "        mpos = np.zeros(num_indices)\n",
    "        lpos = np.zeros(num_indices)\n",
    "        mlastpos = np.zeros(num_indices)\n",
    "        same = np.zeros(num_indices, dtype=bool)\n",
    "        normative_sides = []\n",
    "        all_resp = np.zeros((num_indices, n))\n",
    "\n",
    "\n",
    "        for idx, tidx in enumerate(indices):\n",
    "            \n",
    "            pos = data[:, tidx].copy()\n",
    "\n",
    "            invis = np.sum(pos[1:] == 0)\n",
    "            pos[-invis:] = np.nan\n",
    "\n",
    "            lastpos = pos[-invis - 1]\n",
    "            visible_pos = pos[~np.isnan(pos)]\n",
    "            n_visible = len(visible_pos)\n",
    "\n",
    "            meanpos = np.nanmean(pos)\n",
    "            n_tail = max(1, int(n_visible * 0.1))\n",
    "            last_10pct_mean = np.mean(visible_pos[-n_tail:])\n",
    "\n",
    "            mpos[idx] = meanpos\n",
    "            lpos[idx] = lastpos\n",
    "            mlastpos[idx] = last_10pct_mean\n",
    "            same[idx] = meanpos * lastpos > 0\n",
    "\n",
    "            if \"iid\" in condition_name:\n",
    "                normative = np.sign(meanpos)\n",
    "            else:\n",
    "                normative = np.sign(lastpos)\n",
    "\n",
    "            nmdl[idx] = normative\n",
    "                        \n",
    "            if \"iid\" in condition_name:\n",
    "                value = meanpos\n",
    "            else:  # RDW\n",
    "                value = lastpos\n",
    "            normative_side = 1 if value < 0 else 0\n",
    "            normative_sides.append(normative_side)\n",
    "\n",
    "            for k in range(n):\n",
    "            #for k in trange(n, leave=False, desc=f\"Sim {condition_name} file {file_idx} traj {idx}\"):\n",
    "                npos = pos + np.random.randn(len(pos)) * noise + np.random.randn() * nbias\n",
    "                segment = npos[-(invis + nsmooth):-invis] if invis > 0 else npos[-nsmooth:]\n",
    "                if len(segment) == 0 or np.isnan(segment).any():\n",
    "                    resp = 0\n",
    "                else:\n",
    "                    resp = np.sign(np.mean(segment))\n",
    "\n",
    "                all_resp[idx, k] = resp\n",
    "\n",
    "            rmdl[idx] = np.sum(all_resp[idx, :] * normative > 0) / n\n",
    "        normative_sides = np.array(normative_sides)\n",
    "        df_result = pd.DataFrame({\n",
    "            'trajectory_id': indices[:len(rmdl)],\n",
    "            'condition': [condition_name] * len(rmdl),\n",
    "            'rmdl': rmdl,\n",
    "            'nmdl': nmdl,\n",
    "            'normative_side':  normative_sides.reshape(-1),\n",
    "            'meanpos': mpos,\n",
    "            'lastpos': lpos,\n",
    "            'last10pct': mlastpos,\n",
    "            'same_sign': same.astype(int)\n",
    "        })\n",
    "\n",
    "        df_resp = pd.DataFrame(all_resp)\n",
    "        df_results_all[condition_name] = df_result\n",
    "        os.makedirs(\"../data/sbpm_outputs_new_path_28\", exist_ok=True)\n",
    "        condition = condition_name.replace(\" \", \"_\")\n",
    "        filename = f\"../data/sbpm_outputs_new_path_46_2/sbpm_pred_on_new_{condition}_{file_idx}.csv\"\n",
    "        \n",
    "        #df_result.to_csv(f\"{out_base}_summary.csv\", sep='\\t', index=False)\n",
    "        df_result.to_csv(filename, sep='\\t',index=False)\n",
    "        #print(f'file for {condition_name}_{file_idx} saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16346e3b-ba82-47ba-94de-bc1dc4c6f34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4543830-216c-491c-a50d-bbeeac8c1ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
